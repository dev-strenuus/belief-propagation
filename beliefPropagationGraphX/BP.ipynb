{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Message\n",
       "defined class Node\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class Message(source: Long, value: (Double, Double))\n",
    "case class Node(typeOfNode: Int, neighbors: Int, distribution: Array[Double], messages: List[Message], firstDestination: Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileName = ../data/input.txt\n",
       "lines = Array(5 5, 0 1, 0.25 0.25 0.25 0.25, 1 2 3, 0.16706443914081145 0.01909307875894988 0.18138424821002386 0.1431980906921241 0.02386634844868735 0.15513126491646778 0.07159904534606205 0.2386634844868735, 2, 0.4 0.6, 3 4, 0.20 0.30 0.40 0.10, 3, 0.25 0.75)\n",
       "variablesNumber = 5\n",
       "factorsNumber = 5\n",
       "variablesNumber = 5\n",
       "factorsNumber = 5\n",
       "tempNodes = Array((0,Node(0,0,null,List(),-1)), (1,Node(0,0,null,List(),-1)), (2,Node(0,0,null,List(),-1)), (3,Node(0,0,null,List(),-1)), (4,Node(0,0,null,List(),-1)), (5,Node(1,0,[D@147c94e,List(),-1)), (6,Node(1,0,[D@19b574ba,List(),-1)), (7,Node(1,0,[D@45c7fd5d,List(),-1)), (8,Node(1,0,[D@aa38070,List(),-1)), (9,Node(1,0,[D@359135d3,List(),-1)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tempEdges:...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array((0,Node(0,0,null,List(),-1)), (1,Node(0,0,null,List(),-1)), (2,Node(0,0,null,List(),-1)), (3,Node(0,0,null,List(),-1)), (4,Node(0,0,null,List(),-1)), (5,Node(1,0,[D@147c94e,List(),-1)), (6,Node(1,0,[D@19b574ba,List(),-1)), (7,Node(1,0,[D@45c7fd5d,List(),-1)), (8,Node(1,0,[D@aa38070,List(),-1)), (9,Node(1,0,[D@359135d3,List(),-1)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fileName = \"../data/input.txt\"\n",
    "var lines = sc.textFile(fileName).collect()\n",
    "var variablesNumber: Long = 0\n",
    "var factorsNumber: Long = 0\n",
    "variablesNumber = lines(0).split(\" \")(0).toLong\n",
    "factorsNumber = lines(0).split(\" \")(1).toLong\n",
    "var tempNodes: Array[(Long, Node)] = new Array[(Long, Node)]((variablesNumber+factorsNumber).toInt) // (id, (type, leaf, distribution))\n",
    "for (a <- 0 to (variablesNumber+factorsNumber - 1).toInt){\n",
    "    tempNodes(a) = (a.toLong, Node(0,0, null, List[Message](), -1))\n",
    "}\n",
    "var tempEdges: Array[Edge[(Long)]] = new Array[Edge[(Long)]](((variablesNumber+factorsNumber-1)*2).toInt)\n",
    "var cont = 0\n",
    "for (a <- 1 to lines.size-1){\n",
    "    if(a%2 == 1){\n",
    "        val factorNode = variablesNumber + ((a-1)/2).toLong\n",
    "        var pos = 0\n",
    "        for (variableNode <- lines(a).split(\" \")){\n",
    "            tempEdges(cont) = Edge(variableNode.toLong, factorNode, 0)\n",
    "            cont = cont + 1\n",
    "            tempEdges(cont) = Edge(factorNode, variableNode.toLong, pos)\n",
    "            cont = cont + 1\n",
    "            pos = pos + 1\n",
    "        } \n",
    "    }else{\n",
    "        val distribution:  Array[Double] = lines(a).split(\" \").map(_.toDouble)\n",
    "        val factorNode = (variablesNumber + ((a-1)/2).toLong).toInt\n",
    "        tempNodes(factorNode) = (factorNode, Node(1, 0, distribution, List[Message](), -1))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nodes = ParallelCollectionRDD[2] at parallelize at <console>:39\n",
       "edges = ParallelCollectionRDD[3] at parallelize at <console>:40\n",
       "graph = org.apache.spark.graphx.impl.GraphImpl@409347b1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@409347b1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nodes: RDD[(VertexId, Node)] = sc.parallelize(tempNodes)\n",
    "val edges: RDD[Edge[Long]] = sc.parallelize(tempEdges)\n",
    "val graph = Graph(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inDegrees = VertexRDDImpl[19] at RDD at VertexRDD.scala:57\n",
       "graphWithLeaves = org.apache.spark.graphx.impl.GraphImpl@38b80b60\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@38b80b60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inDegrees: VertexRDD[Int] = graph.inDegrees\n",
    "//leaves.collect().foreach(println)\n",
    "val graphWithLeaves = graph.joinVertices(inDegrees){\n",
    " case (id, node, neighbors) =>  Node(node.typeOfNode, neighbors, node.distribution, node.messages, node.firstDestination)\n",
    "}\n",
    "//graphWithLeaves.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getValueFromDistribution: (distribution: Array[Double], pos: Array[Int])Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getValueFromDistribution(distribution: Array[Double], pos: Array[Int]): Double = {\n",
    "    -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computeProductOfMessagesForVariableNode: (sourceNode: Node)(Double, Double)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def computeProductOfMessagesForVariableNode(sourceNode: Node): (Double, Double) = {\n",
    "    var product: (Double, Double) = (1,1)\n",
    "    for(msg <- sourceNode.messages){\n",
    "        product = (product._1*msg.value._1, product._2*msg.value._2)\n",
    "    }\n",
    "    product\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computeMessageToFactor: (sourceId: Long, sourceNode: Node, destinationId: Long)Message\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def computeMessageToFactor(sourceId: Long, sourceNode: Node, destinationId: Long): Message = {\n",
    "    if(sourceNode.messages.size == sourceNode.neighbors - 1){\n",
    "        val firstDestination = sourceNode.firstDestination\n",
    "        if(firstDestination == destinationId)\n",
    "            Message(sourceId, computeProductOfMessagesForVariableNode(sourceNode))\n",
    "        else\n",
    "            null\n",
    "    }else if(sourceNode.messages.size == sourceNode.neighbors){\n",
    "        val product: (Double, Double) = computeProductOfMessagesForVariableNode(sourceNode)\n",
    "        if(destinationId == sourceNode.firstDestination)\n",
    "            null\n",
    "        else{\n",
    "            for(msg <- sourceNode.messages){\n",
    "                if(msg.source == destinationId){\n",
    "                    Message(sourceId, (product._1/msg.value._1, product._2/msg.value._2))\n",
    "                }\n",
    "            }\n",
    "            null //should not happen\n",
    "        }\n",
    "    }else{\n",
    "        null\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computeMessageToVariable: (sourceId: Long, sourceNode: Node, destinationId: Long)Message\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def computeMessageToVariable(sourceId: Long, sourceNode: Node, destinationId: Long): Message = {\n",
    "    return null\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mergeMsg: (msg1: List[Message], msg2: List[Message])List[Message]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mergeMsg(msg1: List[Message], msg2: List[Message]): List[Message] = msg1:::msg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vprog: (vertexId: org.apache.spark.graphx.VertexId, value: Node, message: List[Message])Node\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vprog(vertexId: VertexId, value: Node, message: List[Message]): Node = {\n",
    "    if(message.head.source == -1){\n",
    "        Node(value.typeOfNode, value.neighbors, value.distribution, value.messages, value.firstDestination)\n",
    "    }\n",
    "    else{\n",
    "       \n",
    "        val newMessages = value.messages:::message\n",
    "        var firstDestination: Long = -1\n",
    "        if(value.messages.size == value.neighbors && message.size == 1)\n",
    "            firstDestination = message.head.source\n",
    "        Node(value.typeOfNode, value.neighbors, value.distribution, newMessages, firstDestination)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sendMsg: (triplet: org.apache.spark.graphx.EdgeTriplet[Node,Long])Iterator[(org.apache.spark.graphx.VertexId, List[Message])]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//tofix\n",
    "def sendMsg(triplet: EdgeTriplet[Node, Long]): Iterator[(VertexId, List[Message])] = {\n",
    "    val sourceId = triplet.srcId\n",
    "    val sourceNode = triplet.srcAttr\n",
    "    val destinationId = triplet.dstId\n",
    "    if(sourceNode.messages.size == 0){\n",
    "        if(sourceNode.neighbors == 1){\n",
    "            if(sourceNode.typeOfNode == 0)\n",
    "                Iterator((destinationId, List(Message(sourceId, (1,1)))))\n",
    "            else\n",
    "                Iterator((destinationId, List(Message(sourceId, (getValueFromDistribution(sourceNode.distribution, Array(0)), getValueFromDistribution(sourceNode.distribution, Array(1)))))))\n",
    "        }else{\n",
    "            Iterator.empty\n",
    "        }\n",
    "    }else{\n",
    "        if(sourceNode.neighbors == 1){\n",
    "            Iterator.empty\n",
    "        }else{\n",
    "            if(sourceNode.typeOfNode == 0)\n",
    "                Iterator((destinationId, List(computeMessageToFactor(sourceId, sourceNode, destinationId))))\n",
    "            else\n",
    "                Iterator((destinationId, List(computeMessageToVariable(sourceId, sourceNode, destinationId))))\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val initialMsg = Message(-1, (-1, -1))\n",
    "val maxIterations = (variablesNumber+factorsNumber)*2\n",
    "val finalGraph = graph.pregel(initialMsg, maxIterations, EdgeDirection.Out)(vprog, sendMsg, mergeMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
